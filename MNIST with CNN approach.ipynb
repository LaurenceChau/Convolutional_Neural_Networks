{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26b075119e8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(arr):\n",
    "    d = []\n",
    "    for a in arr:\n",
    "        dummy = np.zeros(10)\n",
    "        dummy[a] = 1\n",
    "        d.append(dummy)\n",
    "    return np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y_test = one_hot_encoder(y_test)\n",
    "onehot_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y_train = one_hot_encoder(y_train)\n",
    "onehot_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn graph.PNG\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input\n",
    "reshape\n",
    "convolution layer 1\n",
    "sampling 1\n",
    "convolution layer 2\n",
    "sampling 2\n",
    "reshape\n",
    "dnn layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "learning_rate = 0.0001\n",
    "input_shape = [None, 28, 28]\n",
    "image_shape = [-1, 28, 28, 1]\n",
    "filter1_shape = [6, 6, 1, 32]\n",
    "filter2_shape = [6, 6, 32, 64]\n",
    "pooling_window_size = [1, 2, 2, 1]\n",
    "n_output = 10\n",
    "n_epoch = 6\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init weight func\n",
    "def init_weight(shape):\n",
    "    init_weight = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(init_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init bias func\n",
    "def init_bias(shape):\n",
    "    init_bias = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input layer\n",
    "input_x = tf.placeholder(dtype=tf.float32, shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the input image to image tensor\n",
    "image_x = tf.reshape(input_x, shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution layer 1\n",
    "w1 = init_weight(filter1_shape)\n",
    "b1 = init_bias([filter1_shape[3]])\n",
    "conv2d_1 = tf.nn.conv2d(image_x, w1, strides=[1,1,1,1], padding='SAME')\n",
    "conv_layer_1 = tf.nn.relu(conv2d_1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling layre 1\n",
    "pooling_1 = tf.nn.max_pool(conv_layer_1, ksize=pooling_window_size, strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution layer 2\n",
    "w2 = init_weight(filter2_shape)\n",
    "b2 = init_bias([filter2_shape[3]])\n",
    "conv2d_2 = tf.nn.conv2d(pooling_1, w2, strides=[1,1,1,1], padding='SAME')\n",
    "conv_layer_2 = tf.nn.relu(conv2d_2 + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling layre 2\n",
    "pooling_2 = tf.nn.max_pool(conv_layer_2, ksize=pooling_window_size, strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_input = tf.reshape(pooling_2,shape=[-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully Connected Layer\n",
    "w3 = init_weight([7*7*64, 1024])\n",
    "b3 = init_bias([1024])\n",
    "dnn_layer = tf.nn.relu(tf.matmul(reshape_input, w3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop out layer\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "drop_out_layer = tf.nn.dropout(dnn_layer, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "w_out = init_weight([1024, n_output])\n",
    "b_out = init_bias([n_output])\n",
    "y_output = tf.matmul(drop_out_layer, w_out) + b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch:  0\n",
      "accuracy after 0 steps: \n",
      "0.0961\n",
      "accuracy after 100 steps: \n",
      "0.8312\n",
      "accuracy after 200 steps: \n",
      "0.9047\n",
      "accuracy after 300 steps: \n",
      "0.9239\n",
      "accuracy after 400 steps: \n",
      "0.9348\n",
      "accuracy after 500 steps: \n",
      "0.9437\n",
      "accuracy after 600 steps: \n",
      "0.9508\n",
      "accuracy after 700 steps: \n",
      "0.9535\n",
      "accuracy after 800 steps: \n",
      "0.9545\n",
      "accuracy after 900 steps: \n",
      "0.9582\n",
      "accuracy after 1000 steps: \n",
      "0.9592\n",
      "accuracy after 1100 steps: \n",
      "0.9655\n",
      "number of epoch:  1\n",
      "accuracy after 0 steps: \n",
      "0.96\n",
      "accuracy after 100 steps: \n",
      "0.9679\n",
      "accuracy after 200 steps: \n",
      "0.965\n",
      "accuracy after 300 steps: \n",
      "0.9703\n",
      "accuracy after 400 steps: \n",
      "0.9702\n",
      "accuracy after 500 steps: \n",
      "0.9721\n",
      "accuracy after 600 steps: \n",
      "0.9737\n",
      "accuracy after 700 steps: \n",
      "0.9729\n",
      "accuracy after 800 steps: \n",
      "0.973\n",
      "accuracy after 900 steps: \n",
      "0.9746\n",
      "accuracy after 1000 steps: \n",
      "0.9757\n",
      "accuracy after 1100 steps: \n",
      "0.9775\n",
      "number of epoch:  2\n",
      "accuracy after 0 steps: \n",
      "0.9744\n",
      "accuracy after 100 steps: \n",
      "0.977\n",
      "accuracy after 200 steps: \n",
      "0.975\n",
      "accuracy after 300 steps: \n",
      "0.9791\n",
      "accuracy after 400 steps: \n",
      "0.9791\n",
      "accuracy after 500 steps: \n",
      "0.9791\n",
      "accuracy after 600 steps: \n",
      "0.9795\n",
      "accuracy after 700 steps: \n",
      "0.9777\n",
      "accuracy after 800 steps: \n",
      "0.9768\n",
      "accuracy after 900 steps: \n",
      "0.9809\n",
      "accuracy after 1000 steps: \n",
      "0.9812\n",
      "accuracy after 1100 steps: \n",
      "0.9819\n",
      "number of epoch:  3\n",
      "accuracy after 0 steps: \n",
      "0.9809\n",
      "accuracy after 100 steps: \n",
      "0.9825\n",
      "accuracy after 200 steps: \n",
      "0.9803\n",
      "accuracy after 300 steps: \n",
      "0.9835\n",
      "accuracy after 400 steps: \n",
      "0.9836\n",
      "accuracy after 500 steps: \n",
      "0.9835\n",
      "accuracy after 600 steps: \n",
      "0.9843\n",
      "accuracy after 700 steps: \n",
      "0.9838\n",
      "accuracy after 800 steps: \n",
      "0.984\n",
      "accuracy after 900 steps: \n",
      "0.9849\n",
      "accuracy after 1000 steps: \n",
      "0.9839\n",
      "accuracy after 1100 steps: \n",
      "0.985\n",
      "number of epoch:  4\n",
      "accuracy after 0 steps: \n",
      "0.983\n",
      "accuracy after 100 steps: \n",
      "0.9849\n",
      "accuracy after 200 steps: \n",
      "0.9832\n",
      "accuracy after 300 steps: \n",
      "0.9857\n",
      "accuracy after 400 steps: \n",
      "0.9861\n",
      "accuracy after 500 steps: \n",
      "0.9864\n",
      "accuracy after 600 steps: \n",
      "0.987\n",
      "accuracy after 700 steps: \n",
      "0.9845\n",
      "accuracy after 800 steps: \n",
      "0.9853\n",
      "accuracy after 900 steps: \n",
      "0.9856\n",
      "accuracy after 1000 steps: \n",
      "0.986\n",
      "accuracy after 1100 steps: \n",
      "0.9869\n",
      "number of epoch:  5\n",
      "accuracy after 0 steps: \n",
      "0.9849\n",
      "accuracy after 100 steps: \n",
      "0.9875\n",
      "accuracy after 200 steps: \n",
      "0.9832\n",
      "accuracy after 300 steps: \n",
      "0.9874\n",
      "accuracy after 400 steps: \n",
      "0.9875\n",
      "accuracy after 500 steps: \n",
      "0.9881\n",
      "accuracy after 600 steps: \n",
      "0.9879\n",
      "accuracy after 700 steps: \n",
      "0.9886\n",
      "accuracy after 800 steps: \n",
      "0.9864\n",
      "accuracy after 900 steps: \n",
      "0.9884\n",
      "accuracy after 1000 steps: \n",
      "0.9882\n",
      "accuracy after 1100 steps: \n",
      "0.9882\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(n_epoch):\n",
    "        print('number of epoch: ', e)\n",
    "        steps = int(X_train.shape[0]/batch_size)\n",
    "        for i in range(steps):\n",
    "            X_batch = X_train[i*batch_size: i*batch_size + batch_size]\n",
    "            y_batch = onehot_y_train[i*batch_size:i*batch_size + batch_size]\n",
    "            sess.run(train, feed_dict={input_x:X_batch, hold_prob:0.5, y_true:y_batch})\n",
    "            #calcuate the accuracy:\n",
    "            if i % 100 == 0:\n",
    "                matches = tf.equal(tf.argmax(y_output, 1), tf.argmax(onehot_y_test, 1))\n",
    "                acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "                print('accuracy after {} steps: '.format(i))\n",
    "                print(sess.run(acc, feed_dict={input_x:X_test, hold_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
